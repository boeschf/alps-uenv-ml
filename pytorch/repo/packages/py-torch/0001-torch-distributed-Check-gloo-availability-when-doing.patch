From 636a898b39699ae2e4bbb04617e4b73e46dea6c8 Mon Sep 17 00:00:00 2001
From: Kiuk Chung <kiuk@google.com>
Date: Fri, 19 Apr 2024 04:07:00 +0000
Subject: [PATCH] =?UTF-8?q?[torch/distributed]=20Check=20gloo=20availabili?=
 =?UTF-8?q?ty=20when=20doing=20isinstance(pg,=E2=80=A6=20(#124233)?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Fixes a bug where a reference to `_ProcessGroupWrapper` is used without first checking whether gloo is available. This fails on pytorch builds that do not include gloo becuase `_ProcessGroupWrapper` is only pybinded when building with `USE_GLOO=1`. Therefore, creation of a new process group fails with a `NameError` when only NCCL is available as the backend.

Pull Request resolved: https://github.com/pytorch/pytorch/pull/124233
Approved by: https://github.com/rohan-varma, https://github.com/d4l3k
---
 test/distributed/test_pg_wrapper.py   | 34 +++++++++++++++++++++++++++
 torch/distributed/distributed_c10d.py |  4 +++-
 2 files changed, 37 insertions(+), 1 deletion(-)

diff --git a/test/distributed/test_pg_wrapper.py b/test/distributed/test_pg_wrapper.py
index 1305ddd042..d7e59f1c90 100644
--- a/test/distributed/test_pg_wrapper.py
+++ b/test/distributed/test_pg_wrapper.py
@@ -3,15 +3,19 @@
 import os
 import sys
 from datetime import timedelta
+from unittest.mock import patch
 
 import torch
 import torch.distributed as c10d
+from torch._C._distributed_c10d import _ProcessGroupWrapper
+
 
 if not c10d.is_available():
     print("c10d not available, skipping tests", file=sys.stderr)
     sys.exit(0)
 
 from test_c10d_common import LOOPBACK
+
 from torch.testing._internal.common_distributed import (
     create_device,
     MultiProcessTestCase,
@@ -346,6 +350,36 @@ if not TEST_WITH_DEV_DBG_ASAN:
             pg.allreduce([torch.ones(1, device=dev)])
             pg._end_coalescing(torch.device(dev))
 
+        @requires_nccl()
+        @skip_if_lt_x_gpu(2)
+        @with_dist_debug_levels(levels=["DETAIL"])
+        @patch("torch.distributed.distributed_c10d._GLOO_AVAILABLE", False)
+        def test_debug_level_detail_no_gloo(self):
+            with self.assertRaisesRegex(
+                AssertionError, "ProcessGroupWrapper unsupported without GLOO backend"
+            ):
+                self._create_wrapper_pg()
+
+        @requires_nccl()
+        @skip_if_lt_x_gpu(2)
+        @patch("torch.distributed.distributed_c10d._GLOO_AVAILABLE", False)
+        def test_new_group_no_gloo(self):
+            def patched_isinstance(obj, clazz):
+                if clazz is _ProcessGroupWrapper:
+                    raise NameError
+                else:
+                    return isinstance(obj, clazz)
+
+            with patch(
+                "torch.distributed.distributed_c10d.isinstance",
+                side_effect=patched_isinstance,
+            ):
+                self._create_wrapper_pg(with_new_group=True)
+                # nothing to assert, isinstance(pg, _ProcessGroupWrapper)
+                # should never be invoked since it is preceeded by
+                # _GLOO_AVAILABLE check, this test will fail on
+                # an unexpected NameError if not.
+
 
 @requires_gloo()
 class ProcessGroupGlooWrapperTest(AbstractProcessGroupWrapperTest):
diff --git a/torch/distributed/distributed_c10d.py b/torch/distributed/distributed_c10d.py
index 99727a4f05..ea417b55de 100644
--- a/torch/distributed/distributed_c10d.py
+++ b/torch/distributed/distributed_c10d.py
@@ -1380,7 +1380,7 @@ def _get_split_source(pg):
 
     # If necessary, find a backend to split from by peeling process
     # group wrappers from our potentially wrapped process group.
-    while isinstance(split_from, _ProcessGroupWrapper):
+    while _GLOO_AVAILABLE and isinstance(split_from, _ProcessGroupWrapper):
         split_from = split_from.wrapped_pg
 
     return split_from
@@ -3771,6 +3771,8 @@ def _create_process_group_wrapper(
     world_size: int,
     timeout: timedelta = default_pg_timeout,
 ):
+    assert _GLOO_AVAILABLE, "ProcessGroupWrapper unsupported without GLOO backend."
+
     # (whc) this appears to be just for the gloo backend? if so, `default_pg_timeout` is appropriate...
 
     # Create a separate prefix store for the helper process group.
-- 
2.35.3

